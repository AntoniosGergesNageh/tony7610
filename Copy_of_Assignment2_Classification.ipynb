{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tony7610/tony7610/blob/main/Copy_of_Assignment2_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6en7d5OBYJMa"
      },
      "source": [
        "# Assignment 2: Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nP3eq_TfYJMf"
      },
      "source": [
        "# Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "MyEx_G_DYJMg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import sklearn.linear_model\n",
        "import sklearn.tree\n",
        "import sklearn.metrics\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSOuipFDYJMh"
      },
      "source": [
        "# Starter code students need to edit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "WZBTBNQoYJMi"
      },
      "outputs": [],
      "source": [
        "def calc_TP_TN_FP_FN(ytrue_N, yhat_N):\n",
        "    ''' Compute counts of four possible outcomes of a binary classifier for evaluation.\n",
        "    \n",
        "    Args\n",
        "    ----\n",
        "    ytrue_N : 1D array of floats\n",
        "        Each entry represents the binary value (0 or 1) of 'true' label of one example\n",
        "        One entry per example in current dataset\n",
        "    yhat_N : 1D array of floats\n",
        "        Each entry represents a predicted binary value (either 0 or 1).\n",
        "        One entry per example in current dataset.\n",
        "        Needs to be same size as ytrue_N.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    TP : float\n",
        "        Number of true positives\n",
        "    TN : float\n",
        "        Number of true negatives\n",
        "    FP : float\n",
        "        Number of false positives\n",
        "    FN : float\n",
        "        Number of false negatives\n",
        "        \n",
        "    '''\n",
        "    #THIS THE SOLUTION ----------------->\n",
        "    TP = 0.0\n",
        "    FP = 0.0\n",
        "    TN = 0.0\n",
        "    FN = 0.0\n",
        "\n",
        "    for i in range(len(yhat_N)): \n",
        "        if ytrue_N[i]==yhat_N[i]==1:\n",
        "           TP += 1\n",
        "        if yhat_N[i]==1 and ytrue_N[i]!=yhat_N[i]:\n",
        "           FP += 1\n",
        "        if ytrue_N[i]==yhat_N[i]==0:\n",
        "           TN += 1\n",
        "        if yhat_N[i]==0 and ytrue_N[i]!=yhat_N[i]:\n",
        "           FN += 1\n",
        "\n",
        "    return TP, TN, FP, FN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGPdR_I_YJMi"
      },
      "source": [
        "# Starter code that should be used as is.\n",
        "\n",
        "No need to edit these functions!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "lT9UoLdzYJMj"
      },
      "outputs": [],
      "source": [
        "def calc_perf_metrics_for_threshold(ytrue_N, yproba1_N, thresh):\n",
        "    ''' Compute performance metrics for a given probabilistic classifier and threshold\n",
        "    '''\n",
        "    tp, tn, fp, fn = calc_TP_TN_FP_FN(ytrue_N, yproba1_N >= thresh)\n",
        "    ## Compute ACC, TPR, TNR, etc.\n",
        "    acc = (tp + tn) / float(tp + tn + fp + fn + 1e-10)\n",
        "    tpr = tp / float(tp + fn + 1e-10)\n",
        "    tnr = tn / float(fp + tn + 1e-10)\n",
        "    ppv = tp / float(tp + fp + 1e-10)\n",
        "    npv = tn / float(tn + fn + 1e-10)\n",
        "    \n",
        "    return acc, tpr, tnr, ppv, npv\n",
        "\n",
        "def print_perf_metrics_for_threshold(ytrue_N, yproba1_N, thresh):\n",
        "    ''' Pretty print perf. metrics for a given probabilistic classifier and threshold\n",
        "    '''\n",
        "    acc, tpr, tnr, ppv, npv = calc_perf_metrics_for_threshold(ytrue_N, yproba1_N, thresh)\n",
        "    \n",
        "    ## Pretty print the results\n",
        "    print(\"%.3f ACC\" % acc)\n",
        "    print(\"%.3f TPR\" % tpr)\n",
        "    print(\"%.3f TNR\" % tnr)\n",
        "    print(\"%.3f PPV\" % ppv)\n",
        "    print(\"%.3f NPV\" % npv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Z7M5ytnRYJMk"
      },
      "outputs": [],
      "source": [
        "def calc_confusion_matrix_for_threshold(ytrue_N, yproba1_N, thresh):\n",
        "    ''' Compute the confusion matrix for a given probabilistic classifier and threshold\n",
        "    \n",
        "    Args\n",
        "    ----\n",
        "    ytrue_N : 1D array of floats\n",
        "        Each entry represents the binary value (0 or 1) of 'true' label of one example\n",
        "        One entry per example in current dataset\n",
        "    yproba1_N : 1D array of floats\n",
        "        Each entry represents a probability (between 0 and 1) that correct label is positive (1)\n",
        "        One entry per example in current dataset\n",
        "        Needs to be same size as ytrue_N\n",
        "    thresh : float\n",
        "        Scalar threshold for converting probabilities into hard decisions\n",
        "        Calls an example \"positive\" if yproba1 >= thresh\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    cm_df : Pandas DataFrame\n",
        "        Can be printed like print(cm_df) to easily display results\n",
        "    '''\n",
        "    cm = sklearn.metrics.confusion_matrix(ytrue_N, yproba1_N >= thresh)\n",
        "    cm_df = pd.DataFrame(data=cm, columns=[0, 1], index=[0, 1])\n",
        "    cm_df.columns.name = 'Predicted'\n",
        "    cm_df.index.name = 'True'\n",
        "    return cm_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "0aBgWVzxYJMk"
      },
      "outputs": [],
      "source": [
        "def compute_perf_metrics_across_thresholds(ytrue_N, yproba1_N, thresh_grid=None):\n",
        "    ''' Compute common binary classifier performance metrics across many thresholds\n",
        "    \n",
        "    If no array of thresholds is provided, will use all 'unique' values\n",
        "    in the yproba1_N array to define all possible thresholds with different performance.\n",
        "    \n",
        "    Args\n",
        "    ----\n",
        "    ytrue_N : 1D array of floats\n",
        "        Each entry represents the binary value (0 or 1) of 'true' label of one example\n",
        "        One entry per example in current dataset\n",
        "    yproba1_N : 1D array of floats\n",
        "        Each entry represents a probability (between 0 and 1) that correct label is positive (1)\n",
        "        One entry per example in current dataset\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    thresh_grid : 1D array of floats\n",
        "        One entry for each possible threshold\n",
        "    perf_dict : dict, with key, value pairs:\n",
        "        * 'acc' : 1D array of accuracy values (one per threshold)\n",
        "        * 'ppv' : 1D array of positive predictive values (one per threshold)\n",
        "        * 'npv' : 1D array of negative predictive values (one per threshold)\n",
        "        * 'tpr' : 1D array of true positive rates (one per threshold)\n",
        "        * 'tnr' : 1D array of true negative rates (one per threshold)\n",
        "    '''\n",
        "    if thresh_grid is None:\n",
        "        bin_edges = np.linspace(0, 1.001, 21)\n",
        "        thresh_grid = np.sort(np.hstack([bin_edges, np.unique(yproba1_N)]))\n",
        "    tpr_grid = np.zeros_like(thresh_grid)\n",
        "    tnr_grid = np.zeros_like(thresh_grid)\n",
        "    ppv_grid = np.zeros_like(thresh_grid)\n",
        "    npv_grid = np.zeros_like(thresh_grid)\n",
        "    acc_grid = np.zeros_like(thresh_grid)\n",
        "    for tt, thresh in enumerate(thresh_grid):\n",
        "        # Apply specific threshold to convert probas into hard binary values (0 or 1)\n",
        "        # Then count number of true positives, true negatives, etc.\n",
        "        # Then compute metrics like accuracy and true positive rate\n",
        "        acc, tpr, tnr, ppv, npv = calc_perf_metrics_for_threshold(ytrue_N, yproba1_N, thresh)\n",
        "        acc_grid[tt] = acc\n",
        "        tpr_grid[tt] = tpr\n",
        "        tnr_grid[tt] = tnr\n",
        "        ppv_grid[tt] = ppv\n",
        "        npv_grid[tt] = npv\n",
        "    return thresh_grid, dict(\n",
        "        acc=acc_grid,\n",
        "        tpr=tpr_grid,\n",
        "        tnr=tnr_grid,\n",
        "        ppv=ppv_grid,\n",
        "        npv=npv_grid)\n",
        "\n",
        "def make_plot_perf_vs_threshold(ytrue_N, yproba1_N, bin_edges=np.linspace(0, 1, 21)):\n",
        "    ''' Make pretty plot of binary classifier performance as threshold increases\n",
        "    \n",
        "    Produces a plot with 3 rows:\n",
        "    * top row: hist of predicted probabilities for negative examples (shaded red)\n",
        "    * middle row: hist of predicted probabilities for positive examples (shaded blue)\n",
        "    * bottom row: line plots of metrics that require hard decisions (ACC, TPR, TNR, etc.)\n",
        "    '''\n",
        "    fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(12, 8))\n",
        "    sns.distplot(\n",
        "        yproba1_N[ytrue_N == 0],\n",
        "        color='r', bins=bin_edges, kde=False, rug=True, ax=axes[0]);\n",
        "    sns.distplot(\n",
        "        yproba1_N[ytrue_N == 1],\n",
        "        color='b', bins=bin_edges, kde=False, rug=True, ax=axes[1]);\n",
        "\n",
        "    thresh_grid, perf_grid = compute_perf_metrics_across_thresholds(ytrue_N, yproba1_N)\n",
        "    axes[2].plot(thresh_grid, perf_grid['acc'], 'k-', label='accuracy')\n",
        "    axes[2].plot(thresh_grid, perf_grid['tpr'], 'b-', label='TPR (recall/sensitivity)')\n",
        "    axes[2].plot(thresh_grid, perf_grid['tnr'], 'g-', label='TNR (specificity)')\n",
        "    axes[2].plot(thresh_grid, perf_grid['ppv'], 'c-', label='PPV (precision)')\n",
        "    axes[2].plot(thresh_grid, perf_grid['npv'], 'm-', label='NPV')\n",
        "    axes[2].legend()\n",
        "    axes[2].set_ylim([0, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2oV-6iBYJMl"
      },
      "source": [
        "# Problem 1: Binary Classifier for Cancer-Risk Screening"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lU_tl23HYJMm"
      },
      "source": [
        "### Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "DSmpdaaPYJMm"
      },
      "outputs": [],
      "source": [
        "# Load 3 feature version of x arrays\n",
        "x_tr_M3 = np.loadtxt('../data_cancer/x_train.csv', delimiter=',', skiprows=1)\n",
        "x_va_N3 = np.loadtxt('../data_cancer/x_valid.csv', delimiter=',', skiprows=1)\n",
        "x_te_N3 = np.loadtxt('../data_cancer/x_test.csv', delimiter=',', skiprows=1)\n",
        "\n",
        "# 2 feature version of x arrays\n",
        "x_tr_M2 = x_tr_M3[:, :2].copy()\n",
        "x_va_N2 = x_va_N3[:, :2].copy()\n",
        "x_te_N2 = x_te_N3[:, :2].copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ebnqqmAzYJMm"
      },
      "outputs": [],
      "source": [
        "y_tr_M = np.loadtxt('../data_cancer/y_train.csv', delimiter=',', skiprows=1)\n",
        "y_va_N = np.loadtxt('../data_cancer/y_valid.csv', delimiter=',', skiprows=1)\n",
        "y_te_N = np.loadtxt('../data_cancer/y_test.csv', delimiter=',', skiprows=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2cvRDMbYJMn"
      },
      "source": [
        "## Problem 1a: Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2pgLZDwYJMn"
      },
      "source": [
        "### **1a(i):** What fraction of the provided patients have cancer in the training set, the validation set, and the test set? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8AkWcYVYJMn",
        "outputId": "57ec21f9-740b-4800-98a2-0108ee3ac4a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "frac has_cancer on TRAIN: 0.000\n",
            "frac has_cancer on VALID: 0.000\n",
            "frac has_cancer on TEST : 0.000\n"
          ]
        }
      ],
      "source": [
        "# THE SOLUTION IS --------------->\n",
        "# I WILL SOLVE IT USING \"np.count_nonzero\" TO Counts the number of non-zero values \n",
        "train_frac = np.count_nonzero(y_tr_M)/len(y_tr_M)\n",
        "valid_frac = np.count_nonzero(y_va_N)/len(y_va_N)\n",
        "test_frac = np.count_nonzero(y_te_N)/len(y_te_N)\n",
        "\n",
        "print(\"frac has_cancer on TRAIN: %.3f\" % train_frac) # TODO edit the printed values\n",
        "print(\"frac has_cancer on VALID: %.3f\" % valid_frac)\n",
        "print(\"frac has_cancer on TEST : %.3f\" % test_frac)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3ZNA2UgYJMo"
      },
      "source": [
        "### **1a(ii):** Looking at the features data contained in the training set 𝑥 array, what feature preprocessing (if any) would you recommend to improve a decision tree's performance?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOKIo2qkYJMo"
      },
      "source": [
        "**ANWSER**:\n",
        "\n",
        "**************************************************************************\n",
        "Data from decision trees often don't need much preparation. However, presuming that they are connected and that we are aware of this relationship, we may combine certain characteristics or classes of data to improve performance. We can merge all three features into one (say, A') if, for instance, features A, B, and C exist and features B and C are subsets or derived features of feature A. This lessens the amount of calculation required and may lead to improved performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvOvca-tYJMo"
      },
      "source": [
        "### 1a(iii): Looking at the features data contained in the training set 𝑥 array, what feature preprocessing (if any) would you recommend to improve logistic regression's performance?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0yLjph_YJMp"
      },
      "source": [
        "**Answer**:\n",
        "By scaling the features in the training set data this will make us able to improve the  performance of logistic regression.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XahbRoeiYJMp"
      },
      "source": [
        "## Problem 1b: The predict-0-always baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LtP3zCqYJMp"
      },
      "source": [
        "### Problem 1b(i): Compute the accuracy of the predict-0-always classifier on validation and test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3uhCfCAYJMp",
        "outputId": "33a25792-3f7b-48f8-c5c2-4fb0886c2ecf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "acc on VALID: 0.000\n",
            "acc on TEST : 0.000\n"
          ]
        }
      ],
      "source": [
        "# ANSWER \n",
        "#****************************************************\n",
        "def compute(data=None,bs_line=None):\n",
        "    TP,TN,FP,FN=calc_TP_TN_FP_FN(data,bs_line)\n",
        "    return float((TP+TN)/(TP+TN+FP+FN))\n",
        "\n",
        "va_zeros=np.zeros(len(y_va_N))\n",
        "va_acc=compute(y_va_N,va_zeros)\n",
        "te_zeros=np.zeros(len(y_te_N))\n",
        "te_acc=compute(y_te_N,te_zeros)\n",
        "print(\"acc on VALID: %.3f\" % va_acc)\n",
        "print(\"acc on TEST : %.3f\" % te_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsQuwCPAYJMp"
      },
      "source": [
        "### Problem 1b(ii): Print a confusion matrix for predict-0-always on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "3rR0JIPBYJMq"
      },
      "outputs": [],
      "source": [
        "#ANSWER COMPLETED\n",
        "calc_confusion_matrix_for_threshold(y_va_N,va_zeros,0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sr_hZNhZYJMq"
      },
      "source": [
        "### Problem 1b(iii): This classifier gets pretty good accuracy! Why wouldn't we want to use it?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ohvc59VtYJMq"
      },
      "source": [
        "**SOLU--------------**:\n",
        "******************************\n",
        " This accuracy is biased towards this sample, i.e: If we have another sample where it is all 1s, we would have an accuracy of 0%, and as a result, is sample-dependent. There is no predictive power that varies between different samples which will not allow us to make meaningful predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ca0V9YT3YJMq"
      },
      "source": [
        "### Problem 1b(iv): For the intended application (screening patients before biopsy), describe the possible mistakes the classifier can make in task-specific terms. What costs does each mistake entail (lost time? lost money? life-threatening harm?). How do you recommend evaluating the classifier to be mindful of these costs?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvV18QqfYJMq"
      },
      "source": [
        "**ANSWER**:\n",
        "***************************** \n",
        "A False Negative occurs when a classifier predicts that a patient does not have cancer but in fact they do for an always-0 predictor. The effects of this might be lethal. We also need to take a closer look at other metrics, such Positive/Negative Predictive Value, in order to have a better set of evaluations. Additionally, a PPV test would reveal that this model has a lower"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGblJvCrYJMq"
      },
      "source": [
        "## 1c : Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MynGbiWyYJMq"
      },
      "source": [
        "### Model Fitting for 1c(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "O5BjalsgYJMq"
      },
      "outputs": [],
      "source": [
        "C_grid = np.logspace(-9, 6, 31)\n",
        "\n",
        "tr_loss_list = list()\n",
        "va_loss_list = list()\n",
        "for C in C_grid:\n",
        "    lr = sklearn.linear_model.LogisticRegression(C=C)\n",
        "\n",
        "#ANSWER COMPLETED\n",
        "    lr.fit(x_tr_M2, y_tr_M)\n",
        "    y_tr_predict = lr.predict_proba(x_tr_M2)[:,1]\n",
        "    tr_loss_list.append(sklearn.metrics.log_loss(y_tr_M, y_tr_predict))\n",
        "    y_va_predict = lr.predict_proba(x_va_N2)[:,1]\n",
        "    va_loss_list.append(sklearn.metrics.log_loss(y_va_N, y_va_predict))\n",
        "\n",
        "#ANSWER COMPLETED\n",
        "print(C_grid[np.argmin(va_loss_list)])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gKPT-1tYJMq"
      },
      "source": [
        "### **1c(i):** Apply your logistic regression code to the \"2 feature\" $x$ data, and make a plot of logistic loss (y-axis) vs. C (x-axis) on the training set and validation set. Which value of $C$ do you prefer? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ri2zMJ3xYJMr",
        "outputId": "3275e984-5cb2-4aec-ecec-adcc192c56f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "best C for LR with 2 feature data: 0.000\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#ANSWER COMPLETED\n",
        "plt.plot(C_grid, tr_loss_list, 'b:', label = 'training')\n",
        "plt.plot(C_grid, va_loss_list, 'rs-', label = 'validation')\n",
        "plt.xlabel('log10(C)')\n",
        "plt.xscale('log')\n",
        "plt.ylabel('logistic loss')\n",
        "plt.ylim([0.0, 0.7])\n",
        "\n",
        "#ANSWER COMPLETED\n",
        "plt.legend()\n",
        "plt.title('Log loss vs C')\n",
        "#ANSWER COMPLETED\n",
        "print(\"best C for LR with 2 feature data: %.3f\" % C_grid[np.argmin(va_loss_list)]) # TODO\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aD8OSYtFYJMr"
      },
      "source": [
        "### **1c(ii):** Make a performance plot that shows how good your probabilistic predictions from the best 1c(i) classifier are on the validation set. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "KZ2wP1LtYJMr"
      },
      "outputs": [],
      "source": [
        "#ANSWER COMPLETED\n",
        "lr = sklearn.linear_model.LogisticRegression(C=C_grid[np.argmin(va_loss_list)])\n",
        "lr.fit(x_tr_M2, y_tr_M)\n",
        "y_va_pred = lr.predict_proba(x_va_N2)[:,1]\n",
        "make_plot_perf_vs_threshold(y_va_N, y_va_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68w_gXpMYJMr"
      },
      "source": [
        "### Model fitting for 1c(iii)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "1t17Wo0vYJMr"
      },
      "outputs": [],
      "source": [
        "#ANSWER COMPLETED\n",
        "C_grid = np.logspace(-9, 6, 31)\n",
        "\n",
        "tr_loss_list = list()\n",
        "va_loss_list = list()\n",
        "for C in C_grid:\n",
        "    lr = sklearn.linear_model.LogisticRegression(C=C)\n",
        "    lr.fit(x_tr_M3, y_tr_M)\n",
        "    y_tr_predict = lr.predict_proba(x_tr_M3)[:,1]\n",
        "    tr_loss_list.append(sklearn.metrics.log_loss(y_tr_M, y_tr_predict))\n",
        "    y_va_predict = lr.predict_proba(x_va_N3)[:,1]\n",
        "    va_loss_list.append(sklearn.metrics.log_loss(y_va_N, y_va_predict))\n",
        "#ANSWER COMPLETED\n",
        "print(C_grid[np.argmin(va_loss_list)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riPYkis3YJMr"
      },
      "source": [
        "### **1c(iii):** Plot of logistic loss (y-axis) vs. C (x-axis) on the training set and validation set. Which value of $C$ do you prefer? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqFs2nJMYJMr",
        "outputId": "702f27ef-e676-4da7-8a99-aa00cd0a2ff1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "best C for LR with 3 feature data: 0.000\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "#ANSWER COMPLETED\n",
        "plt.plot(C_grid, tr_loss_list, 'b:', label = 'training')\n",
        "plt.plot(C_grid, va_loss_list, 'rs-', label = 'validation')\n",
        "plt.xlabel('log10(C)');\n",
        "plt.xscale('log')\n",
        "plt.ylabel('logistic loss');\n",
        "plt.ylim([0.0, 0.7]);\n",
        "#ANSWER COMPLETED\n",
        "plt.legend()\n",
        "plt.title('Log loss vs C')\n",
        "\n",
        "print(\"best C for LR with 3 feature data: %.3f\" % C_grid[np.argmin(va_loss_list)]) # TODO\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IeulfJBYJMs"
      },
      "source": [
        "### Problem 1c(iv):  Make a performance plot that shows how good your probabilistic predictions from the best 1c(iii) classifier are on the validation set.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "W7ho4Go3YJMs"
      },
      "outputs": [],
      "source": [
        "#ANSWER COMPLETED\n",
        "lr = sklearn.linear_model.LogisticRegression(C=C_grid[np.argmin(va_loss_list)])\n",
        "lr.fit(x_tr_M3, y_tr_M)\n",
        "y_va_pred = lr.predict_proba(x_va_N3)[:,1]\n",
        "make_plot_perf_vs_threshold(y_va_N, y_va_pred)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08FepxkbYJMs"
      },
      "source": [
        "## Problem 1d: Decision Tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bjssGyDYJMs"
      },
      "source": [
        "### Model fitting code for decision tree 1d(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "u1MjmTnEYJMs"
      },
      "outputs": [],
      "source": [
        "min_samples_leaf_grid = np.asarray([1, 2, 5, 10, 20, 50, 100, 200, y_tr_M.size])\n",
        "\n",
        "tr_loss_list = list()\n",
        "va_loss_list = list()\n",
        "for min_samples_leaf in min_samples_leaf_grid:\n",
        "    tree = sklearn.tree.DecisionTreeClassifier(\n",
        "        criterion='entropy', min_samples_leaf=min_samples_leaf)\n",
        "    tree.fit(x_tr_M3, y_tr_M)\n",
        "    tree_tr_predict = tree.predict_proba(x_tr_M3)[:,1]\n",
        "    tr_loss_list.append(sklearn.metrics.log_loss(y_tr_M, tree_tr_predict))\n",
        "    tree_va_predict = tree.predict_proba(x_va_N3)[:,1]\n",
        "    va_loss_list.append(sklearn.metrics.log_loss(y_va_N, tree_va_predict))\n",
        "\n",
        "    #ANSWER COMPLETED\n",
        "print(min_samples_leaf_grid[np.argmin(va_loss_list)])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZCDjXm-YJMs"
      },
      "source": [
        "### **1d(i):** Plot of logistic loss (y-axis) vs. min_samples_leaf (x-axis) on the training set and validation set. Which value of min_samples_leaf do you prefer? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9EEmkZmDYJMs",
        "outputId": "e741db7f-df7c-42c8-9d79-831cd42cd9d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "best min_samples_leaf with 3 feature data: 0.000\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# TODO plot\n",
        "#ANSWER COMPLETED\n",
        "plt.plot(min_samples_leaf_grid, tr_loss_list, 'b:', label = 'training')\n",
        "plt.plot(min_samples_leaf_grid, va_loss_list, 'rs-', label = 'validation')\n",
        "plt.xlabel('log10(C)');\n",
        "plt.xlabel('min_samples_leaf');\n",
        "plt.ylabel('logistic loss');\n",
        "plt.ylim([0.0, 1.0]);\n",
        "plt.legend()\n",
        "plt.title('Log loss vs C')\n",
        "\n",
        "print(\"best min_samples_leaf with 3 feature data: %.3f\" % min_samples_leaf_grid[np.argmin(va_loss_list)]) # TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORi73R7UYJMs"
      },
      "source": [
        "###  **1d(ii):** Make a performance plot that shows how good your probabilistic predictions from the best 1c(iii) classifier are on the validation set. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "dEWyHXByYJMt"
      },
      "outputs": [],
      "source": [
        "# TODO call make_plot_perf_vs_threshold\n",
        "#ANSWER COMPLETED\n",
        "tree = sklearn.tree.DecisionTreeClassifier(\n",
        "        criterion='entropy', min_samples_leaf=100)\n",
        "tree.fit(x_tr_M3, y_tr_M)\n",
        "tree_va_predict = tree.predict_proba(x_va_N3)[:,1]\n",
        "make_plot_perf_vs_threshold(y_va_N, tree_va_predict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6n5SDJ6YJMt"
      },
      "source": [
        "# Problem 1e: ROC Curve analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uI4rVP7WYJMt"
      },
      "source": [
        "### Problem 1e(i): ROC on Validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhICht0CYJMt",
        "outputId": "66d49f45-85d6-420f-e69a-611ebc1beb48"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# TODO something like: fpr, tpr, thr = sklearn.metrics.roc_curve(...)\n",
        "#ANSWER COMPLETED\n",
        "lr_2M = sklearn.linear_model.LogisticRegression(C=31.622776601683793)\n",
        "lr_2M.fit(x_tr_M2, y_tr_M)\n",
        "y_va_2M_predict = lr_2M.predict_proba(x_va_N2)[:,1]\n",
        "\n",
        "lr_3M = sklearn.linear_model.LogisticRegression(C=1000000.0)\n",
        "lr_3M.fit(x_tr_M3, y_tr_M)\n",
        "y_va_3M_predict = lr_3M.predict_proba(x_va_N3)[:,1]\n",
        "\n",
        "tree = sklearn.tree.DecisionTreeClassifier(criterion='entropy', min_samples_leaf=100)\n",
        "tree.fit(x_tr_M3, y_tr_M)\n",
        "tree_va_predict = tree.predict_proba(x_va_N3)[:,1]\n",
        "\n",
        "fpr_2M, tpr_2M, thres_2M = sklearn.metrics.roc_curve(y_va_N, y_va_2M_predict)\n",
        "fpr_3M, tpr_3M, thres_3M = sklearn.metrics.roc_curve(y_va_N, y_va_3M_predict)\n",
        "fpr_tr, tpr_tr, thres_tr = sklearn.metrics.roc_curve(y_va_N, tree_va_predict) \n",
        "\n",
        "plt.plot(fpr_2M, tpr_2M, label = '2M')\n",
        "plt.plot(fpr_3M, tpr_3M, label = '3M')\n",
        "plt.plot(fpr_tr, tpr_tr, label = 'Tr')\n",
        "plt.legend()\n",
        "plt.title('TPR vs FPR')\n",
        "plt.ylim([0, 1]);\n",
        "plt.xlabel(\"FPR\");\n",
        "plt.ylabel(\"TPR\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3-qyBOzYJMt"
      },
      "source": [
        "### Problem 1e(ii): ROC on Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrFl2GG6YJMt",
        "outputId": "72f3bfdc-552d-4278-b651-5d2913f0450c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEKCAYAAAAMzhLIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAD4BJREFUeJzt3V+MXHd5h/Hni40LDQkgvEjINiQUB7DSltBVmgoVgkKRYyH7BiFbjSgoxSptqFQQahAVoHDRFkqRUN0GFyL+SBACErBCRr6gQaEI02yU4GKnrraGklWoskCaVg0QAm8vZsKO1ru/nR37zEzs5yNF2nPm7PjNT7YfnzMzZ1NVSJK0lidNegBJ0nQzFJKkJkMhSWoyFJKkJkMhSWoyFJKkps5CkeTWJA8m+fYajyfJh5IsJDme5KVdzSJJGl2XZxQfA3Y3Hr8O2Nn/7yDwDx3OIkkaUWehqKo7gR81DtkHfKJ6jgHPSPKcruaRJI1m8wR/7W3A/QPbi/193195YJKD9M46uOiii37rRS960VgGlKTzxd133/2DqpoZ5XsnGYqssm/V+4lU1WHgMMDs7GzNz893OZcknXeS/Oeo3zvJdz0tAjsGtrcDD0xoFknSGiYZijng9f13P10NPFxVZ1x2kiRNVmeXnpJ8GrgG2JpkEXg38GSAqroFOALsARaAR4A3djWLJGl0nYWiqg6s83gBf9LVry9JOjf8ZLYkqclQSJKaDIUkqclQSJKaDIUkqclQSJKaDIUkqclQSJKaDIUkqclQSJKaDIUkqclQSJKaDIUkqclQSJKaDIUkqclQSJKaDIUkqclQSJKaDIUkqclQSJKaDIUkqclQSJKaDIUkqclQSJKaDIUkqclQSJKaDIUkqclQSJKaDIUkqclQSJKaDIUkqclQSJKaDIUkqclQSJKaDIUkqanTUCTZneRUkoUkN63y+HOT3JHkniTHk+zpch5J0sZ1Fookm4BDwHXALuBAkl0rDvsL4PaquhLYD/x9V/NIkkbT5RnFVcBCVZ2uqkeB24B9K44p4JL+108HHuhwHknSCLoMxTbg/oHtxf6+Qe8Brk+yCBwB3rLaEyU5mGQ+yfzS0lIXs0qS1tBlKLLKvlqxfQD4WFVtB/YAn0xyxkxVdbiqZqtqdmZmpoNRJUlr6TIUi8COge3tnHlp6QbgdoCq+gbwFGBrhzNJkjaoy1DcBexMclmSLfRerJ5bccz3gGsBkryYXii8tiRJU6SzUFTVY8CNwFHgPnrvbjqR5OYke/uHvQ14U5JvAZ8G3lBVKy9PSZImaHOXT15VR+i9SD24710DX58EXtblDJKks+MnsyVJTYZCktRkKCRJTYZCktRkKCRJTYZCktRkKCRJTYZCktRkKCRJTYZCktRkKCRJTYZCktRkKCRJTYZCktRkKCRJTYZCktRkKCRJTYZCktRkKCRJTYZCktRkKCRJTYZCktRkKCRJTYZCktRkKCRJTYZCktRkKCRJTYZCktRkKCRJTYZCktRkKCRJTYZCktRkKCRJTYZCktTUaSiS7E5yKslCkpvWOOZ1SU4mOZHkU13OI0nauM1dPXGSTcAh4PeAReCuJHNVdXLgmJ3AO4CXVdVDSZ7d1TySpNF0eUZxFbBQVaer6lHgNmDfimPeBByqqocAqurBDueRJI2gy1BsA+4f2F7s7xt0OXB5kq8nOZZk92pPlORgkvkk80tLSx2NK0laTZehyCr7asX2ZmAncA1wAPhIkmec8U1Vh6tqtqpmZ2ZmzvmgkqS1dRmKRWDHwPZ24IFVjvliVf2sqr4DnKIXDknSlOgyFHcBO5NclmQLsB+YW3HMF4BXAiTZSu9S1OkOZ5IkbVBnoaiqx4AbgaPAfcDtVXUiyc1J9vYPOwr8MMlJ4A7g7VX1w65mkiRtXKpWvmww3WZnZ2t+fn7SY0jSE0qSu6tqdpTv9ZPZkqQmQyFJajIUkqQmQyFJajIUkqQmQyFJajIUkqQmQyFJatpwKJJsSvL7XQwjSZo+a4YiySVJ3pHk75K8Oj1voXcvpteNb0RJ0iS1fsLdJ4GHgG8Afwi8HdgC7Kuqe8cwmyRpCrRC8fyq+nWAJB8BfgA8t6r+dyyTSZKmQus1ip89/kVV/Rz4jpGQpAtP64ziN5P8D8s/qe6pA9tVVZd0Pp0kaeLWDEVVbRrnIJKk6bRmKJI8Bfgj4AXAceDW/g8jkiRdQFqvUXwcmAX+FdgDfGAsE0mSpkrrNYpdA+96+ijwL+MZSZI0TYZ915OXnCTpAtU6o3hJ/11O0Hunk+96kqQLUCsU36qqK8c2iSRpKrUuPdXYppAkTa3WGcWzk7x1rQer6m87mEeSNGVaodgEPI3lT2ZLki5ArVB8v6puHtskkqSp1HqNwjMJSVIzFNeObQpJ0tRaMxRV9aNxDiJJmk4b/pnZkqQLi6GQJDUZCklSk6GQJDUZCklSk6GQJDUZCklSU6ehSLI7yakkC0luahz32iSVZLbLeSRJG9dZKJJsAg4B1wG7gANJdq1y3MXAnwLf7GoWSdLoujyjuApYqKrTVfUocBuwb5Xj3gu8D/hJh7NIkkbUZSi2AfcPbC/29/1SkiuBHVX1pdYTJTmYZD7J/NLS0rmfVJK0pi5DsdrdZ3/5U/OSPAn4IPC29Z6oqg5X1WxVzc7MzJzDESVJ6+kyFIvAjoHt7cADA9sXA1cAX03yXeBqYM4XtCVpunQZiruAnUkuS7IF2A/MPf5gVT1cVVur6tKquhQ4BuytqvkOZ5IkbVBnoaiqx4AbgaPAfcDtVXUiyc1J9nb160qSzq3Wj0I9a1V1BDiyYt+71jj2mi5nkSSNxk9mS5KaDIUkqclQSJKaDIUkqclQSJKaDIUkqclQSJKaDIUkqclQSJKaDIUkqclQSJKaDIUkqclQSJKaDIUkqclQSJKaDIUkqclQSJKaDIUkqclQSJKaDIUkqclQSJKaDIUkqclQSJKaDIUkqclQSJKaDIUkqclQSJKaDIUkqclQSJKaDIUkqclQSJKaDIUkqclQSJKaDIUkqanTUCTZneRUkoUkN63y+FuTnExyPMlXkjyvy3kkSRvXWSiSbAIOAdcBu4ADSXatOOweYLaqfgP4HPC+ruaRJI2myzOKq4CFqjpdVY8CtwH7Bg+oqjuq6pH+5jFge4fzSJJG0GUotgH3D2wv9vet5Qbgy6s9kORgkvkk80tLS+dwREnSeroMRVbZV6semFwPzALvX+3xqjpcVbNVNTszM3MOR5QkrWdzh8+9COwY2N4OPLDyoCSvAt4JvKKqftrhPJKkEXR5RnEXsDPJZUm2APuBucEDklwJfBjYW1UPdjiLJGlEnYWiqh4DbgSOAvcBt1fViSQ3J9nbP+z9wNOAzya5N8ncGk8nSZqQLi89UVVHgCMr9r1r4OtXdfnrS5LOnp/MliQ1GQpJUpOhkCQ1GQpJUpOhkCQ1GQpJUpOhkCQ1GQpJUpOhkCQ1GQpJUpOhkCQ1GQpJUpOhkCQ1GQpJUpOhkCQ1GQpJUpOhkCQ1GQpJUpOhkCQ1GQpJUpOhkCQ1GQpJUpOhkCQ1GQpJUpOhkCQ1GQpJUpOhkCQ1GQpJUpOhkCQ1GQpJUpOhkCQ1GQpJUpOhkCQ1GQpJUpOhkCQ1dRqKJLuTnEqykOSmVR7/lSSf6T/+zSSXdjmPJGnjOgtFkk3AIeA6YBdwIMmuFYfdADxUVS8APgj8dVfzSJJG0+UZxVXAQlWdrqpHgduAfSuO2Qd8vP/154Brk6TDmSRJG7S5w+feBtw/sL0I/PZax1TVY0keBp4F/GDwoCQHgYP9zZ8m+XYnEz/xbGXFWl3AXItlrsUy12LZC0f9xi5DsdqZQY1wDFV1GDgMkGS+qmbPfrwnPtdimWuxzLVY5losSzI/6vd2eelpEdgxsL0deGCtY5JsBp4O/KjDmSRJG9RlKO4Cdia5LMkWYD8wt+KYOeAP+l+/FvinqjrjjEKSNDmdXXrqv+ZwI3AU2ATcWlUnktwMzFfVHPBR4JNJFuidSewf4qkPdzXzE5Brscy1WOZaLHMtlo28FvEf8JKkFj+ZLUlqMhSSpKapDYW3/1g2xFq8NcnJJMeTfCXJ8yYx5zistxYDx702SSU5b98aOcxaJHld//fGiSSfGveM4zLEn5HnJrkjyT39Pyd7JjFn15LcmuTBtT5rlp4P9dfpeJKXDvXEVTV1/9F78fs/gOcDW4BvAbtWHPPHwC39r/cDn5n03BNci1cCv9r/+s0X8lr0j7sYuBM4BsxOeu4J/r7YCdwDPLO//exJzz3BtTgMvLn/9S7gu5Oeu6O1eDnwUuDbazy+B/gyvc+wXQ18c5jnndYzCm//sWzdtaiqO6rqkf7mMXqfWTkfDfP7AuC9wPuAn4xzuDEbZi3eBByqqocAqurBMc84LsOsRQGX9L9+Omd+puu8UFV30v4s2j7gE9VzDHhGkues97zTGorVbv+xba1jquox4PHbf5xvhlmLQTfQ+xfD+WjdtUhyJbCjqr40zsEmYJjfF5cDlyf5epJjSXaPbbrxGmYt3gNcn2QROAK8ZTyjTZ2N/n0CdHsLj7Nxzm7/cR4Y+v8zyfXALPCKTieanOZaJHkSvbsQv2FcA03QML8vNtO7/HQNvbPMryW5oqr+u+PZxm2YtTgAfKyqPpDkd+h9fuuKqvpF9+NNlZH+3pzWMwpv/7FsmLUgyauAdwJ7q+qnY5pt3NZbi4uBK4CvJvkuvWuwc+fpC9rD/hn5YlX9rKq+A5yiF47zzTBrcQNwO0BVfQN4Cr0bBl5ohvr7ZKVpDYW3/1i27lr0L7d8mF4kztfr0LDOWlTVw1W1taourapL6b1es7eqRr4Z2hQb5s/IF+i90YEkW+ldijo91inHY5i1+B5wLUCSF9MLxdJYp5wOc8Dr++9+uhp4uKq+v943TeWlp+ru9h9POEOuxfuBpwGf7b+e/72q2juxoTsy5FpcEIZci6PAq5OcBH4OvL2qfji5qbsx5Fq8DfjHJH9G71LLG87Hf1gm+TS9S41b+6/HvBt4MkBV3ULv9Zk9wALwCPDGoZ73PFwrSdI5NK2XniRJU8JQSJKaDIUkqclQSJKaDIUkqclQSENK8vMk9w78d2mSa5I83L8r6X1J3t0/dnD/vyX5m0nPL41qKj9HIU2pH1fVSwZ39G9v/7Wqek2Si4B7kzx+n6nH9z8VuCfJ56vq6+MdWTp7nlFI50hV/R9wN/BrK/b/GLiXIW6+Jk0jQyEN76kDl50+v/LBJM+id3+pEyv2P5PePZbuHM+Y0rnlpSdpeGdceur73ST3AL8A/qp/+4hr+vuPAy/s7/+vMc4qnTOGQjp7X6uq16y1P8nlwD/3X6O4d9zDSWfLS09Sx6rq34G/BP580rNIozAU0njcArw8yWWTHkTaKO8eK0lq8oxCktRkKCRJTYZCktRkKCRJTYZCktRkKCRJTYZCktT0/9NkOE6bAx0fAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# TODO something like: fpr, tpr, thr = sklearn.metrics.roc_curve(...)\n",
        "#ANSWER COMPLETED\n",
        "lr_2M = sklearn.linear_model.LogisticRegression(C=31.622776601683793)\n",
        "lr_2M.fit(x_tr_M2, y_tr_M)\n",
        "y_te_2M_predict = lr_2M.predict_proba(x_te_N2)[:,1]\n",
        "\n",
        "lr_3M = sklearn.linear_model.LogisticRegression(C=1000000.0)\n",
        "lr_3M.fit(x_tr_M3, y_tr_M)\n",
        "y_te_3M_predict = lr_3M.predict_proba(x_te_N3)[:,1]\n",
        "\n",
        "tree = sklearn.tree.DecisionTreeClassifier(criterion='entropy', min_samples_leaf=100)\n",
        "tree.fit(x_tr_M3, y_tr_M)\n",
        "tree_te_predict = tree.predict_proba(x_te_N3)[:,1]\n",
        "\n",
        "fpr_2M, tpr_2M, thres_2M = sklearn.metrics.roc_curve(y_te_N, y_te_2M_predict)\n",
        "fpr_3M, tpr_3M, thres_3M = sklearn.metrics.roc_curve(y_te_N, y_te_3M_predict)\n",
        "fpr_tr, tpr_tr, thres_tr = sklearn.metrics.roc_curve(y_te_N, tree_te_predict) \n",
        "\n",
        "plt.plot(fpr_2M, tpr_2M, label = '2M')\n",
        "plt.plot(fpr_3M, tpr_3M, label = '3M')\n",
        "plt.plot(fpr_tr, tpr_tr, label = 'Tr')\n",
        "\n",
        "plt.legend()\n",
        "plt.title('TPR vs FPR')\n",
        "plt.ylim([0, 1]);\n",
        "plt.xlabel(\"FPR\");\n",
        "plt.ylabel(\"TPR\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPllamhHYJMt"
      },
      "source": [
        "### **1e(iii):** Short Answer: Compare the 3-feature LR to 2-feature LR models: does one dominate the other in terms of ROC performance?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7v762iGYJMt"
      },
      "source": [
        "**Answer**: The 3-Feature LR dominates the 2-feature LR at all values of of FPR and TPR."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJcEHJm-YJMu"
      },
      "source": [
        "### **1e(iv):** Short Answer: Compare the 3-feature DTree to 2-feature LR models: does one dominate the other in terms of ROC performance?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CTGkTj4YJMu"
      },
      "source": [
        "**Answer**:  IN the validation set, the 3-Feature DTree has better performance over the 2-Feature LR model from FPR ranges between 0.35 and 0.80 and 2-Feature LR performs better between FPR values 0.00 to 0.35 and 0.80 to 1.00. For the test set, the 3-Feature DTree only consistently outperforms 2-Feature LR between FPR values of 0.30 to 0.55, at other ranges, 2-Feature LR performs better most of the time.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9YMbhMCYJMu"
      },
      "source": [
        "## Problem 1f: Selecting a decision threshold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iw4hXIHVYJMu"
      },
      "source": [
        "### Problem 1f(i): Use default 0.5 threshold. Report perf. for 3-feature Logistic Regr."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgGJBXjpYJMu",
        "outputId": "9c13f7db-cd3a-453e-fe75-39ed7afde425"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ON THE VALIDATION SET:\n",
            "Chosen best thr = 0.5000\n",
            "\n",
            "ON THE TEST SET:\n",
            "\n"
          ]
        }
      ],
      "source": [
        "best_thr = 0.5\n",
        "\n",
        "\n",
        "print(\"ON THE VALIDATION SET:\")\n",
        "print(\"Chosen best thr = %.4f\" % best_thr)\n",
        "print(\"\")\n",
        "print(\"ON THE TEST SET:\")\n",
        "# TODO: print(calc_confusion_matrix_for_threshold(...))\n",
        "print(calc_confusion_matrix_for_threshold(y_te_N, y_te_3M_predict, best_thr))\n",
        "print(\"\")\n",
        "# TODO: print(print_perf_metrics_for_threshold(...))\n",
        "print_perf_metrics_for_threshold(y_te_N, y_te_3M_predict, best_thr)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fERXfcmkYJMu"
      },
      "source": [
        "### Problem 1f(ii): Pick threshold to maximize TPR s.t. PPV >= 0.98. Report perf. for 3-feature Logistic Regr."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3LdxxOOYJMu",
        "outputId": "3ccbf158-ac86-44d4-eede-01b5d65a978e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ON THE VALIDATION SET:\n",
            "Chosen best thr = 0.0000\n",
            "\n",
            "ON THE TEST SET:\n",
            "\n"
          ]
        }
      ],
      "source": [
        "thresh = [0.6, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69,0.7,0.9,1.0]\n",
        "\n",
        "chosen_thres = 0.61\n",
        "\n",
        "print(\"ON THE VALIDATION SET:\")\n",
        "print(\"Chosen best thr = %.4f\" % chosen_thres) # TODO\n",
        "print(\"\")\n",
        "print(\"ON THE TEST SET:\")\n",
        "# TODO: print(calc_confusion_matrix_for_threshold(...))\n",
        "print(calc_confusion_matrix_for_threshold(y_te_N, y_te_3M_predict, chosen_thres))\n",
        "print(\"\")\n",
        "# TODO: print(print_perf_metrics_for_threshold(...))\n",
        "print_perf_metrics_for_threshold(y_te_N, y_te_3M_predict, chosen_thres)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kp1Z9kEeYJMv"
      },
      "source": [
        "### Problem 1f(iii): Pick threshold to maximize PPV s.t. TPR >= 0.98. Report perf. for 3-feature Logistic Regr."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHsY0BTvYJMv",
        "outputId": "8a9be670-6319-4e82-dc93-47d2c853edac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ON THE VALIDATION SET:\n",
            "Chosen best thr = 0.0000\n",
            "\n",
            "ON THE TEST SET:\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# TODO thresh_grid, perf_grid = compute_perf_metrics_across_thresholds(...)\n",
        "\n",
        "# TODO Find threshold that makes TPR as large as possible, while satisfying PPV >= 0.98\n",
        "max_ppv = 0.03\n",
        "\n",
        "\n",
        "print(\"ON THE VALIDATION SET:\")\n",
        "print(\"Chosen best thr = %.4f\" % 0.0) # TODO\n",
        "print(\"\")\n",
        "print(\"ON THE TEST SET:\")\n",
        "# TODO: print(calc_confusion_matrix_for_threshold(...))\n",
        "print(calc_confusion_matrix_for_threshold(y_te_N, y_te_3M_predict, max_ppv))\n",
        "\n",
        "print(\"\")\n",
        "# TODO: print(print_perf_metrics_for_threshold(...))\n",
        "print_perf_metrics_for_threshold(y_te_N, y_te_3M_predict, max_ppv)\n",
        "thresh = [0.0029,0.03, 0.0301,0.031]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omyBpEt1YJMw"
      },
      "source": [
        "### Problem 1f(iv): Compare the confusion matrices between 1f(i) - 1f(iii). Which thresholding strategy best meets our preferences from 1a: avoid life-threatening mistakes at all costs, while also eliminating unnecessary biopsies?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dg8B18gFYJMw"
      },
      "source": [
        "**Answer**: \n",
        "For the confusion matrix in subproblem (1f(i)), a default threshold of 0.5 was used, which resulted in a TPR of .440, a TNR of .961, a FPR (false positive rate) of .039, and a FNR (false negative rate) of .56. For the confusion matrix in subproblem (b), TPR was maximized while PPV >= .98. This resulted in a chosen best threshold of .7302, which resulted in a TPR of .280, a TNR of 1.0, a FPR of 0, and a FNR of .72. For the confusion matrix in subproblem (1f(c)), where PPV was maximized while TPR >= .98, in which the best threshold is .0186, the TPR is 1.0, the TNR is .471, the FPR is .53, and the FNR is 0. The false positive rate is a type 1 error, and the false negative rate is a type 2 error. The cost that matters the most in these three cases is the false negative rate, a type 2 error which means a patient is falsely predicted to not have cancer when they do actually have it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bmo-6RdtYJMw"
      },
      "source": [
        "### Problem 1f(v): How many subjects in the test set are saved from unnecessary biopsies using your selected thresholding strategy? What fraction of current biopsies would be avoided if this classifier was adopted by the hospital?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leh-pXqRYJMw"
      },
      "source": [
        "**Answer**:\n",
        "\n",
        " The model that maximises PPV while guaranteeing TPR >=.98 yields the optimal threshold of.0186 if we were to hold the cost of a type 2 error greater than that of a type 1 error, as in the example above in subproblem (1f(v)). The FPR would be.53 if the hospital applied this classifier, which would suggest that 47% of all biopsies—or 1 FPR biopsy—could be avoided.\n",
        "\n",
        "->57 individuals were spared from performing pointless biopsies. The avoided portion is 57/155.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "OLWzUTXCYJMw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "DvSnv6GrYJMx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yxeLRmqYJMx"
      },
      "source": [
        "# Problem 2: Concept Questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZB0m2ITYJMx"
      },
      "source": [
        "### 2a(i): Where is the ideal minimum of the function $f(x)$?\n",
        "When f(x) = 0, the ideal minimum occurs at x = 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbwD70smYJMx"
      },
      "source": [
        "### 2a(i): Where is the ideal minimum of the function $f(x)$?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otxSe8koYJMx"
      },
      "source": [
        "### 2a(ii): Does this gradient descent procedure converge? Explain your answer.M\n",
        "It won't converge; instead, it will go backward and forth with steps that range from -0.1 to 0.1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2DJnZI0YJMx"
      },
      "source": [
        "\n",
        "### 2a(iii): Can you propose a step length with which the optimization procedure converges?\n",
        "Since we are unable to determine the gradient of f(x) when f(x) = 0, we are unable to provide a constant step length where the gradient will converge to 0.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIUFmlM8YJMx"
      },
      "source": [
        "## Problem 2b: Understanding Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WvDm3fRYJMx"
      },
      "source": [
        "### 2b(i): Explain why the illustration has problems (1-3 sentences).\n",
        "\n",
        "Answer: In order to predict y values for given x values, logistic regression identifies a set of weights (w) and biases (b) to be filled in. The regression border ought to therefore be a straight line by nature. The graph, however, displays a sigmoid curve, which should reflect the logistic sigmoid function rather than the graph of logistic regression.\n",
        "Another Answer: The graph depicts a sigmoid curve, and logistic regression identifies weights and biases that will be applied to the x values to forecast the output value. The boundaries of the choice will be a line."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "cwkiAMjwYJMy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "o3ZNA2UgYJMo",
        "QvOvca-tYJMo",
        "9LtP3zCqYJMp",
        "zsQuwCPAYJMp",
        "Sr_hZNhZYJMq",
        "Ca0V9YT3YJMq",
        "MynGbiWyYJMq",
        "4gKPT-1tYJMq",
        "aD8OSYtFYJMr",
        "68w_gXpMYJMr",
        "riPYkis3YJMr",
        "9IeulfJBYJMs",
        "5bjssGyDYJMs",
        "eZCDjXm-YJMs",
        "ORi73R7UYJMs",
        "uI4rVP7WYJMt",
        "X3-qyBOzYJMt",
        "OPllamhHYJMt",
        "bJcEHJm-YJMu",
        "Iw4hXIHVYJMu",
        "fERXfcmkYJMu",
        "Kp1Z9kEeYJMv",
        "omyBpEt1YJMw",
        "Bmo-6RdtYJMw",
        "SbwD70smYJMx",
        "otxSe8koYJMx",
        "v2DJnZI0YJMx",
        "3WvDm3fRYJMx"
      ],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}